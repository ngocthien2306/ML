{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.preprocessing import OneHotEncoder      \n",
    "from statistics import mean\n",
    "from sklearn.model_selection import KFold   \n",
    "import joblib \n",
    "#endregion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]: PART 2. GET THE DATA (DONE). LOAD DATA\n",
    "raw_data = pd.read_excel('datasets/NguyenNgocThien_19110148_Week03_Data.xlsx')\n",
    "\n",
    "# In[3]: PART 3. DISCOVER THE DATA TO GAIN INSIGHTS\n",
    "#region\n",
    "# 3.1 Quick view of the data\n",
    "print('\\n____________ Dataset info ____________')\n",
    "print(raw_data.info())              \n",
    "print('\\n____________ Some first data examples ____________')\n",
    "print(raw_data.head(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n____________ Counts on a feature ____________')\n",
    "club = raw_data['Club'].value_counts()\n",
    "print(club) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Watch_Info_Data(raw_data): \n",
    "    \n",
    "    print('\\n____________ Dataset info ____________')\n",
    "    print(raw_data.info())              \n",
    "    print('\\n____________ Some first data examples ____________')\n",
    "    print(raw_data.head(10)) \n",
    "    \n",
    "    print('\\n____________ Counts on a feature ____________')\n",
    "    league = raw_data['League'].value_counts()\n",
    "    club = raw_data['Club'].value_counts()\n",
    "    nation = raw_data['Nation'].value_counts()\n",
    "    print(league) \n",
    "    print(club) \n",
    "    print(nation) \n",
    "    \n",
    "    print('\\n____________ Statistics of numeric features ____________')\n",
    "    describe = raw_data.describe()\n",
    "    print(describe)    \n",
    "    \n",
    "    print('\\n____________ Get specific rows and cols ____________')     \n",
    "    print(raw_data.loc[[0,5,20], ['Player', 'Value', 'Gls','League']] ) # Refer using column name\n",
    "    print(raw_data.iloc[[0,5,20], [2, 8]] ) # Refer using column ID\n",
    "  \n",
    "# 3.2 Scatter plot b/w 2 features\n",
    "def Show_Data_OneChart_Scatter(raw_data, x, y):\n",
    "    raw_data.plot(kind=\"scatter\", y=y, x=x, alpha=0.2)\n",
    "    #plt.axis([0, 5, 0, 10000])\n",
    "    plt.savefig('figures/scatter_1_feat.png', format='png', dpi=300)\n",
    "    plt.show()      \n",
    "\n",
    "def Show_Data_ManyCharts_Fix(raw_data, features):\n",
    "    # 3.3 Scatter plot b/w every pair of features\n",
    "    from pandas.plotting import scatter_matrix   \n",
    "    features_to_plot = features\n",
    "    scatter_matrix(raw_data[features_to_plot], figsize=(12, 8)) # Note: histograms on the main diagonal\n",
    "    plt.savefig('figures/scatter_mat_all_feat.png', format='png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "def Show_Data_Histogram(raw_data, features):\n",
    "    # 3.4 Plot histogram of 1 feature\n",
    "    from pandas.plotting import scatter_matrix   \n",
    "    features_to_plot = features\n",
    "    scatter_matrix(raw_data[features_to_plot], figsize=(12, 8)) # Note: histograms on the main diagonal\n",
    "    plt.show()\n",
    "\n",
    "    # 3.5 Plot histogram of numeric features\n",
    "    #raw_data.hist(bins=10, figsize=(10,5)) #bins: no. of intervals\n",
    "    raw_data.hist(figsize=(10,5)) #bins: no. of intervals\n",
    "    plt.rcParams['xtick.labelsize'] = 10\n",
    "    plt.rcParams['ytick.labelsize'] = 10\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/hist_raw_data.png', format='png', dpi=300) # must save before show()\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Data_OneChart_Scatter(raw_data, \"Value\", \"Gls\")\n",
    "Show_Data_OneChart_Scatter(raw_data, \"Total Mins/90\", \"Gls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show_Data_ManyCharts_Fix(raw_data, [\"Value\", \"Age\", \"Gls\", \"Ast\", \"Total Mins/90\"])\n",
    "Show_Data_Histogram(raw_data, [\"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = []\n",
    "# 3.6 Compute correlations b/w features\n",
    "def Correlations_Feature(raw_data, index):\n",
    "    corr_matrix = raw_data.corr()\n",
    "    print(corr_matrix) # print correlation matrix\n",
    "    print('\\n',corr_matrix[index].sort_values(ascending=False)) # print correlation b/w a feature and other features\n",
    "\n",
    "# 3.7 Try combining features\n",
    "\n",
    "def Correlations_Combine_Feature(raw_data):\n",
    "    raw_data[\"Gls_By_MP\"] = raw_data[\"Gls\"] / raw_data[\"MP\"] \n",
    "    raw_data[\"Gls_Ast\"] = raw_data[\"Gls\"] + raw_data[\"Ast\"] \n",
    "    corr_matrix = raw_data.corr()\n",
    "    print(corr_matrix[\"Value\"].sort_values(ascending=False)) # print correlation b/w a feature and other features\n",
    "    raw_data.drop(columns = [\"Gls Ast\", \"Gls_By_MP\"], inplace=True) # remove experiment columns\n",
    "    #endregion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    corr_matrix = raw_data.corr()\n",
    "    print(corr_matrix) # print correlation matrix\n",
    "    value = corr_matrix['Value'].sort_values(ascending=False)\n",
    "    print('\\n', value) # print correlation b/w a feature and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"Value by season\"] = raw_data[\"Value\"] / raw_data[\"Contract Years Left\"] \n",
    "raw_data[\"Gls Ast\"] = raw_data[\"Gls\"] + raw_data[\"Ast\"] \n",
    "corr_matrix = raw_data.corr()\n",
    "print(corr_matrix[\"Value by season\"].sort_values(ascending=False)) # print correlation b/w a feature and other features\n",
    "raw_data.drop(columns = [\"Gls Ast\", \"Value by season\"], inplace=True) # remove experiment columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop(columns = [\"Player\", \"Value Player\", \"Nation\", \"Min\", \"Starts\", \"Yellow Cards\", \"Red Cards\", \"Non-Penalty Goals\", \"Penalties Scored\", \"Penalties Attempted\", \"Non-Penalty Goals/90\", \"(Gls+Ast-Scored Penalties)/90\", \"Squad\", \"Gls/90\", \"Ast/90\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[\"Interval Value\"] = pd.cut(raw_data[\"Value\"],\n",
    "      bins=[0, 20000, 40000, 60000, 80000, 100000, np.inf],\n",
    "      #labels=[\"<20 tr\", \"20-40 tr\", \"40-60 tr\", \"60-80 tr\", \"80-100 tr\", \">100 tr\"])\n",
    "      labels=[2,4,6,8,10, 100]) # use numeric labels to plot histogram\n",
    "  \n",
    "  # Create training and test set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  \n",
    "splitter = StratifiedShuffleSplit(n_splits=4, test_size=0.2, random_state=42) # n_splits: no. of re-shuffling & splitting = no. of train-test sets \n",
    "                                                                                # (if you want to run the algorithm n_splits times with different train-test set)\n",
    "for train_index, test_index in splitter.split(raw_data, raw_data[\"Interval Value\"]): # Feature \"KHOẢNG GIÁ\" must NOT contain NaN\n",
    "    train_set = raw_data.loc[train_index]\n",
    "    test_set = raw_data.loc[test_index]      \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # See if it worked as expected\n",
    "\n",
    "raw_data[\"Interval Value\"].hist(bins=6, figsize=(5,5));\n",
    "train_set[\"Interval Value\"].hist(bins=6, figsize=(5,5)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.info())\n",
    "for _set_ in (train_set, test_set):\n",
    "    #_set_.drop(\"income_cat\", axis=1, inplace=True) # axis=1: drop cols, axis=0: drop rows\n",
    "    _set_.drop(columns=\"Interval Value\", inplace=True) \n",
    "print(train_set.info())\n",
    "print(test_set.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n____________ Split training and test set ____________')     \n",
    "print(len(train_set), \"training +\", len(test_set), \"test examples\")\n",
    "print(train_set.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_labels = train_set[\"Value\"].copy()\n",
    "train_set = train_set.drop(columns = \"Value\") \n",
    "test_set_labels = test_set[\"Value\"].copy()\n",
    "test_set = test_set.drop(columns = \"Value\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "    def fit(self, dataframe, labels=None):\n",
    "        return self\n",
    "    def transform(self, dataframe):\n",
    "        return dataframe[self.feature_names].values         \n",
    "\n",
    "num_feat_names = ['Age', 'Contract Years Left', \"MP\", \"Total Mins/90\", \"Gls\", \"Ast\", \"(G+A)/90\",] # =list(train_set.select_dtypes(include=[np.number]))\n",
    "cat_feat_names = [ 'Club', 'Position', \"League\"] # =list(train_set.select_dtypes(exclude=[np.number])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(cat_feat_names)),\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value = \"NO INFO\", copy=True)), # complete missing values. copy=False: imputation will be done in-place \n",
    "    ('cat_encoder', OneHotEncoder()) # convert categorical data into one-hot vectors\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_feat_values_1 = cat_pipeline.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, add_Gls_Ast = True): # MUST NO *args or **kargs\n",
    "      self.add_Gls_Ast = add_Gls_Ast\n",
    "  def fit(self, feature_values, labels = None):\n",
    "      return self  # nothing to do here\n",
    "  def transform(self, feature_values, labels = None):\n",
    "      if self.add_Gls_Ast:        \n",
    "          gls_id, ast_id = 1, 2 # column indices in num_feat_names. can't use column names b/c the transformer SimpleImputer removed them\n",
    "          # NOTE: a transformer in a pipeline ALWAYS return dataframe.values (ie., NO header and row index)\n",
    "          \n",
    "          Total = feature_values[:, gls_id] + feature_values[:, ast_id]\n",
    "          feature_values = np.c_[feature_values, Total] #concatenate np arrays\n",
    "      return feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(num_feat_names)),\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"median\", copy=True)), # copy=False: imputation will be done in-place \n",
    "    ('attribs_adder', MyFeatureAdder(add_Gls_Ast = True)),\n",
    "    ('std_scaler', StandardScaler(with_mean=True, with_std=True, copy=True)) # Scale features to zero mean and unit variance\n",
    "    ])  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4.5 Combine features transformed by two above pipelines\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline) ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_set_val = full_pipeline.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n____________ Processed feature values ____________')\n",
    "print(processed_train_set_val[[0, 1, 2],:].toarray())\n",
    "print(processed_train_set_val.shape)\n",
    "print('We have %d numeric feature + 1 added features + 35 cols of onehotvector for categorical features.' %(len(num_feat_names)))\n",
    "joblib.dump(full_pipeline, r'models/full_pipeline_football.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 10: \n",
    "    onehot_cols = []\n",
    "    for val_list in full_pipeline.transformer_list[1][1].named_steps['cat_encoder'].categories_: \n",
    "        onehot_cols = onehot_cols + val_list.tolist()\n",
    "    columns_header = train_set.columns.tolist() + [\"add_Gls_Ast\"] + onehot_cols\n",
    "    for name in cat_feat_names:\n",
    "        columns_header.remove(name)\n",
    "    processed_train_set = pd.DataFrame(processed_train_set_val.toarray(), columns = columns_header)\n",
    "    print('\\n____________ Processed dataframe ____________')\n",
    "    print(processed_train_set.info())\n",
    "    print(processed_train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "print('\\n____________ LinearRegression ____________')\n",
    "print('Learned parameters: ', model.coef_)\n",
    "\n",
    "# 5.1.2 Compute R2 score and root mean squared error\n",
    "def r2score_and_rmse(model, train_data, labels): \n",
    "    r2score = model.score(train_data, labels)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    prediction = model.predict(train_data)\n",
    "    mse = mean_squared_error(labels, prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return r2score, rmse      \n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "        \n",
    "# 5.1.3 Predict labels for some training instances\n",
    "print(\"\\nInput data: \\n\", train_set.iloc[0:9])\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # new lib\n",
    "def store_model(model, model_name = \"\"):\n",
    "    # NOTE: sklearn.joblib faster than pickle of Python\n",
    "    # INFO: can store only ONE object in a file\n",
    "    if model_name == \"\": \n",
    "        model_name = type(model).__name__\n",
    "    joblib.dump(model,'models/' + model_name + '_model.pkl')\n",
    "def load_model(model_name):\n",
    "    # Load objects into memory\n",
    "    #del model\n",
    "    model = joblib.load('models/' + model_name + '_model.pkl')\n",
    "    #print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_model(model, \"full_pipeline_football\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "# Compute R2 score and root mean squared error\n",
    "print('\\n____________ DecisionTreeRegressor ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "store_model(model, \"full_pipeline_football\")\n",
    "# Predict labels for some training instances\n",
    "#print(\"Input data: \\n\", train_set.iloc[0:9])\n",
    "\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[10:20]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[10:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 5.3 Try RandomForestRegressor model\n",
    "# Training (NOTE: may take time if train_set is large)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 5) # n_estimators: no. of trees\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "# Compute R2 score and root mean squared error\n",
    "print('\\n____________ RandomForestRegressor ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "store_model(model, 'full_pipeline_football')      \n",
    "# Predict labels for some training instances\n",
    "print(\"Input data: \\n\", train_set.iloc[0:9])\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_feat_adder = PolynomialFeatures(degree = 2) # add high-degree features to the data\n",
    "train_set_poly_added = poly_feat_adder.fit_transform(processed_train_set_val)\n",
    "new_training = 10\n",
    "if new_training == 10:\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_set_poly_added, train_set_labels)\n",
    "    store_model(model, model_name = \"PolinomialRegression\")      \n",
    "else:\n",
    "    model = load_model(\"PolinomialRegression\")\n",
    "# 5.4.2 Compute R2 score and root mean squared error\n",
    "print('\\n____________ Polinomial regression ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, train_set_poly_added, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "# 5.4.3 Predict labels for some training instances\n",
    "print(\"\\nPredictions: \", model.predict(train_set_poly_added[10:20]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[10:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 5.5 Evaluate with K-fold cross validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#cv1 = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42); \n",
    "#cv2 = StratifiedKFold(n_splits=10, random_state=42); \n",
    "#cv3 = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42); \n",
    "print('\\n____________ K-fold cross validation ____________')\n",
    "\n",
    "run_evaluation = 1\n",
    "if run_evaluation == 1:\n",
    "    from sklearn.model_selection import KFold, StratifiedKFold\n",
    "    # NOTE: \n",
    "    #   + If data labels are float, cross_val_score use KFold() to split cv data.\n",
    "    #   + KFold randomly splits data, hence does NOT ensure data splits are the same (only StratifiedKFold may ensure that)\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=37) # cv data generator: just a try to persist data splits (hopefully)\n",
    "\n",
    "    # Evaluate LinearRegression\n",
    "    model_name = \"LinearRegression\" \n",
    "    model = LinearRegression()             \n",
    "    nmse_scores = cross_val_score(model, processed_train_set_val, train_set_labels, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-nmse_scores)\n",
    "    joblib.dump(rmse_scores,'saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"LinearRegression rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "\n",
    "    # Evaluate DecisionTreeRegressor\n",
    "    model_name = \"DecisionTreeRegressor\" \n",
    "    model = DecisionTreeRegressor()\n",
    "    nmse_scores = cross_val_score(model, processed_train_set_val, train_set_labels, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-nmse_scores)\n",
    "    joblib.dump(rmse_scores,'saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"DecisionTreeRegressor rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "\n",
    "    # Evaluate RandomForestRegressor\n",
    "    model_name = \"RandomForestRegressor\" \n",
    "    model = RandomForestRegressor(n_estimators = 5)\n",
    "    nmse_scores = cross_val_score(model, processed_train_set_val, train_set_labels, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-nmse_scores)\n",
    "    joblib.dump(rmse_scores,'saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"RandomForestRegressor rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "\n",
    "    # Evaluate Polinomial regression\n",
    "    model_name = \"PolinomialRegression\" \n",
    "    model = LinearRegression()\n",
    "    nmse_scores = cross_val_score(model, train_set_poly_added, train_set_labels, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-nmse_scores)\n",
    "    joblib.dump(rmse_scores,'saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"Polinomial regression rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "else:\n",
    "    # Load rmse\n",
    "    model_name = \"LinearRegression\" \n",
    "    rmse_scores = joblib.load('saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"\\nLinearRegression rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "\n",
    "    model_name = \"DecisionTreeRegressor\" \n",
    "    rmse_scores = joblib.load('saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"DecisionTreeRegressor rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "\n",
    "    model_name = \"RandomForestRegressor\" \n",
    "    rmse_scores = joblib.load('saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"RandomForestRegressor rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')\n",
    "\n",
    "    model_name = \"PolinomialRegression\" \n",
    "    rmse_scores = joblib.load('saved_objects/' + model_name + '_rmse.pkl')\n",
    "    print(\"Polinomial regression rmse: \", rmse_scores.round(decimals=1))\n",
    "    print(\"Avg. rmse: \", mean(rmse_scores.round(decimals=1)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n____________ Fine-tune models ____________')\n",
    "def print_search_result(grid_search, model_name = \"\"): \n",
    "    print(\"\\n====== Fine-tune \" + model_name +\" ======\")\n",
    "    print('Best hyperparameter combination: ',grid_search.best_params_)\n",
    "    print('Best rmse: ', np.sqrt(-grid_search.best_score_))  \n",
    "    #print('Best estimator: ', grid_search.best_estimator_) # NOTE: require refit=True in  SearchCV\n",
    "    print('Performance of hyperparameter combinations:')\n",
    "    cv_results = grid_search.cv_results_\n",
    "    for (mean_score, params) in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "        print('rmse =', np.sqrt(-mean_score).round(decimals=1), params) \n",
    "\n",
    "method = 1\n",
    "# 6.1 Method 1: Grid search (try all combinations of hyperparams in param_grid)\n",
    "if method == 1:\n",
    "    from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "    cv = KFold(n_splits=5,shuffle=True,random_state=37) # cv data generator\n",
    "        \n",
    "    run_new_search = 1      \n",
    "    if run_new_search:        \n",
    "        # 6.1.1 Fine-tune RandomForestRegressor\n",
    "        model = RandomForestRegressor()\n",
    "        param_grid = [\n",
    "            # try 15 (3x4) combinations of hyperparameters (bootstrap=True: drawing samples with replacement)\n",
    "            {'bootstrap': [True], 'n_estimators': [3, 15, 30], 'max_features': [2, 12, 20, 39]},\n",
    "            # then try 12 (4x3) combinations with bootstrap set as False\n",
    "            {'bootstrap': [False], 'n_estimators': [3, 5, 10, 20], 'max_features': [2, 6, 10]} ]\n",
    "            # Train across 5 folds, hence a total of (15+12)*5=135 rounds of training \n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='neg_mean_squared_error', return_train_score=True, \n",
    "        refit=True) # refit=True: after finding best hyperparam, it fit() the model with whole data (hope to get better result)\n",
    "        grid_search.fit(processed_train_set_val, train_set_labels)\n",
    "        joblib.dump(grid_search,'saved_objects/RandomForestRegressor_gridsearch.pkl')\n",
    "        print_search_result(grid_search, model_name = \"RandomForestRegressor\")      \n",
    "\n",
    "        # 6.1.2 Fine-tune Polinomial regression          \n",
    "        model = Pipeline([ ('poly_feat_adder', PolynomialFeatures()), # add high-degree features\n",
    "                           ('lin_reg', LinearRegression()) ]) \n",
    "        param_grid = [\n",
    "            # try 3 values of degree\n",
    "            {'poly_feat_adder__degree': [1, 2, 3]} ] # access param of a transformer: <transformer>__<parameter> https://scikit-learn.org/stable/modules/compose.html\n",
    "            # Train across 5 folds, hence a total of 3*5=15 rounds of training \n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "        grid_search.fit(processed_train_set_val, train_set_labels)\n",
    "        joblib.dump(grid_search,'saved_objects/PolinomialRegression_gridsearch.pkl') \n",
    "        print_search_result(grid_search, model_name = \"PolinomialRegression\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor({})\n",
    "param_grid = [\n",
    "    # try 15 (3x4) combinations of hyperparameters (bootstrap=True: drawing samples with replacement)\n",
    "    {'bootstrap': [True], 'n_estimators': [3, 15, 30], 'max_features': [2, 12, 20, 39]},\n",
    "    # then try 12 (4x3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 5, 10, 20], 'max_features': [2, 6, 10]} ]\n",
    "    # Train across 5 folds, hence a total of (15+12)*5=135 rounds of training \n",
    "grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='neg_mean_squared_error', return_train_score=True, \n",
    "refit=True) # refit=True: after finding best hyperparam, it fit() the model with whole data (hope to get better result)\n",
    "grid_search.fit(processed_train_set_val, train_set_labels)\n",
    "print_search_result(grid_search, model_name = \"RandomForestRegressor\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchs = joblib.load('saved_objects/RandomForestRegressor_gridsearch.pkl')\n",
    "best_model = searchs.best_estimator_\n",
    "# Pick Linear regression\n",
    "#best_model = joblib.load('saved_objects/LinearRegression_model.pkl')\n",
    "\n",
    "print('\\n____________ ANALYZE AND TEST YOUR SOLUTION ____________')\n",
    "print('SOLUTION: ' , best_model)\n",
    "store_model(best_model, model_name=\"SOLUTION\")   \n",
    "\n",
    "# 7.2 Analyse the SOLUTION to get more insights about the data\n",
    "# NOTE: ONLY for rand forest\n",
    "if type(best_model).__name__ == \"RandomForestRegressor\":\n",
    "    # Print features and importance score  (ONLY on rand forest)\n",
    "    feature_importances = best_model.feature_importances_\n",
    "    onehot_cols = []\n",
    "    for val_list in full_pipeline.transformer_list[1][1].named_steps['cat_encoder'].categories_: \n",
    "        onehot_cols = onehot_cols + val_list.tolist()\n",
    "    feature_names = train_set.columns.tolist() + [\"add_Gls_Ast\"] + onehot_cols\n",
    "    for name in cat_feat_names:\n",
    "        feature_names.remove(name)\n",
    "    print('\\nFeatures and importance score: ')\n",
    "    print(*sorted(zip( feature_names, feature_importances.round(decimals=4)), key = lambda row: row[1], reverse=True),sep='\\n')\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on test data:\n",
      "R2 score (on test data, best=1): 1.0\n",
      "Root Mean Square Error:  0.0\n",
      "\n",
      "Test data: \n",
      "                     Club  Age  Position  Contract Years Left          League  \\\n",
      "206          Real Madrid   29  Defender                    4         La Liga   \n",
      "343  Olympique Marseille   27    attack                    1         Ligue 1   \n",
      "620        VfL Wolfsburg   23    attack                    1      Bundesliga   \n",
      "639        Villarreal CF   29  midfield                    1         La Liga   \n",
      "483            Fulham FC   24    attack                    5  Premier League   \n",
      "2      Tottenham Hotspur   28    attack                    3  Premier League   \n",
      "386        Bayern Munich   27  midfield                    1      Bundesliga   \n",
      "457         FC Barcelona   22  midfield                    2         La Liga   \n",
      "539        Celta de Vigo   25    attack                    3         La Liga   \n",
      "\n",
      "       MP  Total Mins/90   Gls   Ast  (G+A)/90  \n",
      "206  13.0           10.6   0.0   2.0      0.19  \n",
      "343  15.0           13.6   9.0   1.0      0.74  \n",
      "620  29.0           20.6   5.0   5.0      0.49  \n",
      "639  35.0           28.1   1.0   6.0      0.25  \n",
      "483   NaN            NaN   NaN   NaN       NaN  \n",
      "2    35.0           34.2  23.0  14.0      1.08  \n",
      "386  16.0            8.7   1.0   0.0      0.12  \n",
      "457  14.0            3.2   1.0   0.0      0.31  \n",
      "539  34.0           26.8  12.0   3.0      0.56  \n",
      "\n",
      "Predictions:  [18000. 40500. 16200. 31500. 36000. 13500. 19800. 45000. 22500.]\n",
      "Labels:       [27000, 19800, 11700, 10800, 15300, 108000, 18000, 16200, 13500] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
